{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pykospacing import Spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../raw/train.csv\")\n",
    "df_v = pd.read_csv(\"../raw/dev.csv\")\n",
    "df_t = pd.read_csv(\"../raw/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boostcamp-sts-v1-test-000</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>가상화폐거래소 폐쇄하지 말고</td>\n",
       "      <td>가상화폐 거래소 폐쇄 반대합니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boostcamp-sts-v1-test-001</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>뇌물적폐1호 640만달라 70억 뇌물받은 권양숙 구속하고 재산을 몰수하라</td>\n",
       "      <td>뇌물적폐 원조 640만달라 70억 뇌물받은 권양숙 구속하고 재산을 몰수하세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boostcamp-sts-v1-test-002</td>\n",
       "      <td>petition-rtt</td>\n",
       "      <td>기무사 영관급의 하극상 정말 이대로 방관하는게 민주주의 인지요</td>\n",
       "      <td>그냥 가만히 있는게 진짜 민주주의인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boostcamp-sts-v1-test-003</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>화까지가 한계였다.</td>\n",
       "      <td>기대가 너무 컸다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boostcamp-sts-v1-test-004</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>왜 혼자 있지.. ㅠㅠ</td>\n",
       "      <td>왜 혼자야.. ㅠㅠ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id            source  \\\n",
       "0  boostcamp-sts-v1-test-000  petition-sampled   \n",
       "1  boostcamp-sts-v1-test-001  petition-sampled   \n",
       "2  boostcamp-sts-v1-test-002      petition-rtt   \n",
       "3  boostcamp-sts-v1-test-003      nsmc-sampled   \n",
       "4  boostcamp-sts-v1-test-004         slack-rtt   \n",
       "\n",
       "                                 sentence_1  \\\n",
       "0                           가상화폐거래소 폐쇄하지 말고   \n",
       "1  뇌물적폐1호 640만달라 70억 뇌물받은 권양숙 구속하고 재산을 몰수하라   \n",
       "2        기무사 영관급의 하극상 정말 이대로 방관하는게 민주주의 인지요   \n",
       "3                                화까지가 한계였다.   \n",
       "4                              왜 혼자 있지.. ㅠㅠ   \n",
       "\n",
       "                                   sentence_2  \n",
       "0                           가상화폐 거래소 폐쇄 반대합니다  \n",
       "1  뇌물적폐 원조 640만달라 70억 뇌물받은 권양숙 구속하고 재산을 몰수하세요  \n",
       "2                      그냥 가만히 있는게 진짜 민주주의인가요?  \n",
       "3                                기대가 너무 컸다...  \n",
       "4                                  왜 혼자야.. ㅠㅠ  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    # 문장 속 / 삭제\n",
    "    text = re.sub(r\"/\", \" \", text)\n",
    "\n",
    "    # 문장 속 ㅋ가 4개 이상 일 경우 ㅋㅋㅋ으로 변경\n",
    "    text = re.sub(r\"ㅋ{4,}\", \"ㅋㅋㅋ\", text)\n",
    "\n",
    "    # 문장 속 ㅎ가 3개 이상인 경우 ㅎ로 변경\n",
    "    text = re.sub(r\"ㅎ{4,}\", \"ㅎㅎㅎ\", text)\n",
    "\n",
    "    # 문장 속 ~가 1개 이상인 경우 ~로 변경\n",
    "    text = re.sub(r\"~{2,}\", \"~\", text)\n",
    "\n",
    "    # 문장 속 ;가 3개 이상인 경우 ;;로 변경\n",
    "    text = re.sub(r\";{3,}\", \";;\", text)\n",
    "\n",
    "    # 문장 속 .가 3개 이상인 경우 ...로 변경\n",
    "    text = re.sub(r\"\\.{4,}\", \"...\", text)\n",
    "\n",
    "    # 문장 속 ,가 3개 이상인 경우 ,,,로 변경\n",
    "    text = re.sub(r\"\\,{4,}\", \",,,\", text)\n",
    "\n",
    "    # 문장 속 !가 3개 이상인 경우 !!!로 변경\n",
    "    text = re.sub(r\"!{4,}\", \"!!!\", text)\n",
    "\n",
    "    # 문장 속 ?가 3개 이상인 경우 ???로 변경\n",
    "    text = re.sub(r\"\\?{4,}\", \"???\", text)\n",
    "\n",
    "    # 문장 속 ^가 3개 이상인 경우 ^^로 변경\n",
    "    text = re.sub(r\"\\^{3,}\", \"^^\", text)\n",
    "\n",
    "    # 문장 속 ㅠ가 3개 이상인 경우 ㅠㅠ로 변경\n",
    "    text = re.sub(r\"ㅠ{3,}\", \"ㅠㅠ\", text)\n",
    "\n",
    "    # 문장 속 ㅜ가 3개 이상인 경우 ㅜㅜ로 변경\n",
    "    text = re.sub(r\"ㅜ{3,}\", \"ㅠㅠ\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 dataset ./train_v1.0.2_clean_spacing.csv 생성\n"
     ]
    }
   ],
   "source": [
    "### train dataset\n",
    "# 띄어쓰기\n",
    "spacing = Spacing()\n",
    "\n",
    "df[\"sentence_1\"] = df[\"sentence_1\"].apply(spacing)\n",
    "df[\"sentence_2\"] = df[\"sentence_2\"].apply(spacing)\n",
    "\n",
    "# 문장 변경\n",
    "df[\"sentence_1\"] = df[\"sentence_1\"].apply(clean_text)\n",
    "df[\"sentence_2\"] = df[\"sentence_2\"].apply(clean_text)\n",
    "\n",
    "if \"sentence_1_clean\" in df.columns:\n",
    "    df.drop(columns=[\"sentence_1_clean\"], inplace=True)\n",
    "\n",
    "if \"sentence_2_clean\" in df.columns:\n",
    "    df.drop(columns=[\"sentence_2_clean\"], inplace=True)\n",
    "\n",
    "output_file = \"./train_v1.0.2_clean_spacing.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"새로운 dataset {output_file} 생성\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9324 entries, 0 to 9323\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            9324 non-null   object \n",
      " 1   source        9324 non-null   object \n",
      " 2   sentence_1    9324 non-null   object \n",
      " 3   sentence_2    9324 non-null   object \n",
      " 4   label         9324 non-null   float64\n",
      " 5   binary-label  9324 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 437.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 dataset ./dev_v1.0.1_clean_spacing.csv 생성\n"
     ]
    }
   ],
   "source": [
    "### vaild dataset\n",
    "# 띄어쓰기\n",
    "df_v[\"sentence_1\"] = df_v[\"sentence_1\"].apply(spacing)\n",
    "df_v[\"sentence_2\"] = df_v[\"sentence_2\"].apply(spacing)\n",
    "\n",
    "# 문장 변경\n",
    "df_v[\"sentence_1\"] = df_v[\"sentence_1\"].apply(clean_text)\n",
    "df_v[\"sentence_2\"] = df_v[\"sentence_2\"].apply(clean_text)\n",
    "\n",
    "\n",
    "\n",
    "if \"sentence_1_clean\" in df.columns:\n",
    "\n",
    "    df_v.drop(columns=[\"sentence_1_clean\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "if \"sentence_2_clean\" in df.columns:\n",
    "\n",
    "    df_v.drop(columns=[\"sentence_2_clean\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "output_file = \"./dev_v1.0.1_clean_spacing.csv\"\n",
    "df_v.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"새로운 dataset {output_file} 생성\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550 entries, 0 to 549\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   id            550 non-null    object \n",
      " 1   source        550 non-null    object \n",
      " 2   sentence_1    550 non-null    object \n",
      " 3   sentence_2    550 non-null    object \n",
      " 4   label         550 non-null    float64\n",
      " 5   binary-label  550 non-null    float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 25.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_v.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새로운 dataset ./test_v1.0.1_clean_spacing.csv 생성\n"
     ]
    }
   ],
   "source": [
    "### test dataset\n",
    "# 띄어쓰기\n",
    "spacing = Spacing()\n",
    "\n",
    "df_t[\"sentence_1\"] = df_t[\"sentence_1\"].apply(spacing)\n",
    "df_t[\"sentence_2\"] = df_t[\"sentence_2\"].apply(spacing)\n",
    "\n",
    "# 문장 변경\n",
    "df_t[\"sentence_1\"] = df_t[\"sentence_1\"].apply(clean_text)\n",
    "df_t[\"sentence_2\"] = df_t[\"sentence_2\"].apply(clean_text)\n",
    "\n",
    "if \"sentence_1_clean\" in df.columns:\n",
    "    df_t.drop(columns=[\"sentence_1_clean\"], inplace=True)\n",
    "\n",
    "if \"sentence_2_clean\" in df.columns:\n",
    "    df_t.drop(columns=[\"sentence_2_clean\"], inplace=True)\n",
    "\n",
    "output_file = \"./test_v1.0.1_clean_spacing.csv\"\n",
    "df_t.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"새로운 dataset {output_file} 생성\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1100 entries, 0 to 1099\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          1100 non-null   object\n",
      " 1   source      1100 non-null   object\n",
      " 2   sentence_1  1100 non-null   object\n",
      " 3   sentence_2  1100 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 34.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from konlpy.tag import Okt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"id\": [\n",
    "        \"boostcamp-sts-v1-train-000\",\n",
    "        \"boostcamp-sts-v1-train-001\",\n",
    "        \"boostcamp-sts-v1-train-002\",\n",
    "        \"boostcamp-sts-v1-train-003\",\n",
    "        \"boostcamp-sts-v1-train-004\",\n",
    "    ],\n",
    "    \"source\": [\n",
    "        \"nsmc-sampled\",\n",
    "        \"slack-rtt\",\n",
    "        \"petition-sampled\",\n",
    "        \"slack-sampled\",\n",
    "        \"slack-sampled\",\n",
    "    ],\n",
    "    \"sentence_1\": [\n",
    "        \"스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~\",\n",
    "        \"앗 제가 접근권한이 없다고 뜹니다;;\",\n",
    "        \"주택청약조건 변경해주세요.\",\n",
    "        \"입사후 처음 대면으로 만나 반가웠습니다.\",\n",
    "        \"뿌듯뿌듯 하네요!!\",\n",
    "    ],\n",
    "    \"sentence_2\": [\n",
    "        \"반전도 있고,사랑도 있고재미도있네요.\",\n",
    "        \"오, 액세스 권한이 없다고 합니다.\",\n",
    "        \"주택청약 무주택기준 변경해주세요.\",\n",
    "        \"화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.\",\n",
    "        \"꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!\",\n",
    "    ],\n",
    "    \"label\": [2.2, 4.2, 2.4, 3.0, 0.0],\n",
    "    \"binary-label\": [0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mecab 형태소 분석기 사용\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석 및 Word2Vec 학습 데이터 준비\n",
    "sentences = [okt.morphs(sentence) for sentence in df[\"sentence_1\"]] + [\n",
    "    okt.morphs(sentence) for sentence in df[\"sentence_2\"]\n",
    "]\n",
    "\n",
    "# Word2Vec 모델 학습\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사 단어 대체 함수\n",
    "def replace_with_similar_words(sentence, model, okt, top_n=5):\n",
    "    words = okt.morphs(sentence)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word in model.wv.key_to_index:  # 모델에 해당 단어가 있는지 확인\n",
    "            try:\n",
    "                # 유사한 단어 중에서 랜덤으로 하나 선택\n",
    "                similar_words = model.wv.most_similar(word, topn=top_n)\n",
    "                similar_word = random.choice(similar_words)[0]\n",
    "                new_words.append(similar_word)\n",
    "            except KeyError:\n",
    "                new_words.append(word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return \" \".join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           id            source  \\\n",
      "0  boostcamp-sts-v1-train-000      nsmc-sampled   \n",
      "1  boostcamp-sts-v1-train-001         slack-rtt   \n",
      "2  boostcamp-sts-v1-train-002  petition-sampled   \n",
      "3  boostcamp-sts-v1-train-003     slack-sampled   \n",
      "4  boostcamp-sts-v1-train-004     slack-sampled   \n",
      "\n",
      "                                          sentence_1  \\\n",
      "0  뿌 ~!~! 로 입사 ~ 한국영 반가웠습니다 만나니 . 로 만나니 있네요 리얼 뿌듯...   \n",
      "1                  스릴 있고 접근 보다가 ~!~! 반가웠습니다 ;; 있네요 .   \n",
      "2                                   들 보다가 사랑 뿌뿌 있고 화   \n",
      "3                         다르네요 스릴 있네요 , 쓰레기 조건 여느 ;;   \n",
      "4                                         뿌듯뿌듯 하네요!!   \n",
      "\n",
      "                              sentence_2  label  binary-label  \n",
      "0  주택 ~!~! 재미 한번 으로만 접근 로 뿌뿌 접근 해주세요 보다가    2.2           0.0  \n",
      "1             차원 한번 뿌뿌 다르네요 뵈어요 들 화상 보다가    4.2           1.0  \n",
      "2               들 으로만 한번 여느 꼬옥 뿌뿌 있네요 청약    2.4           0.0  \n",
      "3            정말 청약 처음 없다고 재미 있고 뿌뿌 주택 청약    3.0           1.0  \n",
      "4                  꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!    0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "# 증강된 데이터셋 생성\n",
    "for idx, row in df.iterrows():\n",
    "    if row[\"label\"] >= 2.0:\n",
    "        df.at[idx, \"sentence_1\"] = replace_with_similar_words(\n",
    "            row[\"sentence_1\"], model, okt\n",
    "        )\n",
    "        df.at[idx, \"sentence_2\"] = replace_with_similar_words(\n",
    "            row[\"sentence_2\"], model, okt\n",
    "        )\n",
    "\n",
    "# 결과 출력\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "level1-semantictextsimilarity-nlp-14-Qc70mCay",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
