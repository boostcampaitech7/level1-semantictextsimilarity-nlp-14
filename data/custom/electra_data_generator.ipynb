{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **snunlp/kr-electra/generator를 이용한 데이터 증강**\n",
    "made by eyeol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 배경 설명\n",
    "\n",
    "문장의 일부 토큰을 유의어로 교체하여 데이터를 증강해보겠다는 아이디어가 팀내에서 나왔음 </br>\n",
    "\n",
    "다른 팀원들은 w2v과 BERT를 이용하여 유의어 교체를 시도했하였고, </br>\n",
    "나는 그것들과 겹치지 않는 방향으로 데이터 증강 방법을 고민해봄\n",
    "\n",
    "snunlp/kr-electra/generator는 electra 모델을 한국어로 학습한 pre-trained 모델로, </br>\n",
    "pre-train할 때 MaskedLM을 사용하기 때문에 유의어 생성에도 유리하고\n",
    "\n",
    "STS task에서 주력으로 쓰던 snunlp/kr-electra/discriminator와 </br>\n",
    "동일한 vocab을 사용한다는 점도 강점이 될 것이라고 봤다. </br>\n",
    "\n",
    "둘다 mecab-ko라는 형태소 분석기로 tokenizing하여 만든 vocab을 사용하기에, </br>\n",
    "사전 학습 당시, 문장의 맥락을 읽는 방법을 비슷하게 학습했을 것이라 생각"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eyeol\\miniconda3\\envs\\sts\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ElectraForMaskedLM, AutoTokenizer, DataCollatorForLanguageModeling\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)  # Python random 시드 고정\n",
    "    np.random.seed(seed)  # Numpy 시드 고정\n",
    "    torch.manual_seed(seed)  # PyTorch 시드 고정 (CPU)\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch 시드 고정 (모든 GPU)\n",
    "    \n",
    "    # CUDA 비결정적 동작 방지 (재현성을 높이기 위해)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# ipynb에서는 cell이 바뀌면 seed 정보가 날라가기 때문에\n",
    "# 학습을 실행하는 셀에서 set.seed(42)를 실행해야 한다\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 불러오기 및 학습\n",
    "\n",
    "그냥 불러온 generator로 유의어를 생성했을 때는 데이터 품질이 너무 좋지 않았다 </br>\n",
    "특정 토큰이 #이나 , 처럼 원래의 문맥과 많이 달라지는 경우가 많았음 </br>\n",
    "\n",
    "그래서 generator를 ElectraForMaskedLM으로 불러오고 </br>\n",
    "train.csv의 sentence_1, sentence_2로 학습시켜서 train set에 오버피팅(?)시켜봤음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 및 토크나이저 불러오기\n",
    "model = ElectraForMaskedLM.from_pretrained(\"snunlp/KR-ELECTRA-generator\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-ELECTRA-generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForMaskedLM(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator_predictions): ElectraGeneratorPredictions(\n",
       "    (activation): GELUActivation()\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=256, out_features=768, bias=True)\n",
       "  )\n",
       "  (generator_lm_head): Linear(in_features=768, out_features=30000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 구조 확인\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.data.iloc[idx]['sentence']\n",
    "        encoding = self.tokenizer(sentence, truncation=True, padding='max_length', max_length=self.max_length, return_tensors=\"pt\")\n",
    "        input_ids = encoding[\"input_ids\"].squeeze()\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze()\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train set을 MaskedLM이 학습할 수 있는 형태로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../raw/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df[\"sentence_1\"].tolist() + df[\"sentence_2\"].tolist()\n",
    "df_new = pd.DataFrame(sentences, columns=[\"sentence\"])\n",
    "df_new.to_csv(\"./v2/combined_sentences.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dev set을 MaskedLM이 평가에 사용할 수 있는 형태로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../raw/dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = df2[\"sentence_1\"].tolist() + df2[\"sentence_2\"].tolist()\n",
    "df_new2 = pd.DataFrame(sentences2, columns=[\"sentence\"])\n",
    "df_new2.to_csv(\"./v2/combined_sentences_dev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLM을 위한 데이터 콜레이터\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15  # 15% 마스킹\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SentencesDataset(df_new, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수와 옵티마이저 설정\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 학습을 위한 스케줄러 설정 (선택 사항, learning rate 스케줄링)\n",
    "num_epochs = 4\n",
    "num_training_steps = num_epochs * len(dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # 설치된 PyTorch 버전 확인\n",
    "print(torch.cuda.is_available())  # CUDA 사용 가능 여부 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForMaskedLM(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator_predictions): ElectraGeneratorPredictions(\n",
       "    (activation): GELUActivation()\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=256, out_features=768, bias=True)\n",
       "  )\n",
       "  (generator_lm_head): Linear(in_features=768, out_features=30000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 GPU로 이동 (가능한 경우)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 완료. Loss: 0.01738937944173813\n",
      "Epoch 2/4 완료. Loss: 0.010741570964455605\n",
      "Epoch 3/4 완료. Loss: 0.011487413197755814\n",
      "Epoch 4/4 완료. Loss: 0.011057838797569275\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "# 모델 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    for batch in dataloader:\n",
    "        # 배치 데이터를 GPU로 이동\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # 모델에 입력하고 출력 계산\n",
    "        outputs = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], labels=batch[\"input_ids\"])\n",
    "        \n",
    "        # 손실 계산 (MLM에서 labels는 input_ids와 동일, 마스크된 토큰에 대해서만 손실을 계산)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # 역전파를 통해 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 옵티마이저를 통해 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 업데이트 (선택 사항)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # 옵티마이저의 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} 완료. Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. dev.csv 파일을 불러와서 Dataset과 DataLoader 생성\n",
    "df_dev = pd.read_csv(\"./v2/combined_sentences_dev.csv\")\n",
    "\n",
    "# Dev Dataset 생성\n",
    "dev_dataset = SentencesDataset(df_dev, tokenizer)\n",
    "\n",
    "# Dev DataLoader 생성\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 평가 함수 정의\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()  # 모델을 평가 모드로 설정 (드롭아웃 비활성화)\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():  # 평가 시에는 그래디언트를 계산하지 않음\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            \n",
    "            # 모델 출력과 손실 계산\n",
    "            outputs = model(input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"], labels=batch[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # 손실 값 누적\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 예측된 토큰과 실제 토큰 비교하여 정확도 계산\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            labels = batch[\"input_ids\"]\n",
    "            \n",
    "            # 마스크된 부분만 정확도 계산 (loss에서는 mask로 손실을 계산했으므로, 동일한 부분만 정확도를 계산)\n",
    "            mask = labels != tokenizer.pad_token_id  # 패딩된 부분을 제외\n",
    "            correct_predictions = (predictions == labels) & mask\n",
    "            accuracy = correct_predictions.sum().item() / mask.sum().item()\n",
    "            total_accuracy += accuracy * mask.sum().item()\n",
    "            total_samples += mask.sum().item()\n",
    "\n",
    "    # 평균 손실과 정확도 계산\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_accuracy = total_accuracy / total_samples\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 평가 실행\n",
    "dev_loss, dev_accuracy = evaluate(model, dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev Loss: 0.0109, Dev Accuracy: 0.9325\n"
     ]
    }
   ],
   "source": [
    "# 4. 평가 결과 출력\n",
    "print(f\"Dev Loss: {dev_loss:.4f}, Dev Accuracy: {dev_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 유의어 생성 및 토큰 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. train.csv 파일을 불러옴\n",
    "df = pd.read_csv(\"../raw/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForMaskedLM(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator_predictions): ElectraGeneratorPredictions(\n",
       "    (activation): GELUActivation()\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=256, out_features=768, bias=True)\n",
       "  )\n",
       "  (generator_lm_head): Linear(in_features=768, out_features=30000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델을 평가 모드로 설정\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForMaskedLM(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator_predictions): ElectraGeneratorPredictions(\n",
       "    (activation): GELUActivation()\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=256, out_features=768, bias=True)\n",
       "  )\n",
       "  (generator_lm_head): Linear(in_features=768, out_features=30000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 사용 설정 (선택 사항)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 유의어로 대체할 토큰 선택 및 교체하는 함수\n",
    "def get_synonym_replacement(sentence, prob=0.15):\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    input_ids = tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # 마스크할 토큰들 선택 (확률적으로)\n",
    "    masked_indices = [\n",
    "        i for i in range(1, len(tokens) - 1)  # [CLS]와 [SEP]를 제외한 중간 토큰들만 대상\n",
    "        if random.random() < prob\n",
    "    ]\n",
    "    \n",
    "    if not masked_indices:  # 마스킹할 토큰이 없으면 원본 문장 반환\n",
    "        return sentence\n",
    "    \n",
    "    # 마스킹된 토큰 생성\n",
    "    for idx in masked_indices:\n",
    "        tokens[idx] = \"[MASK]\"\n",
    "    \n",
    "    # 마스킹된 문장 생성\n",
    "    masked_sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "    masked_input = tokenizer(masked_sentence, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 마스크된 위치에 대한 토큰 예측\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**masked_input)\n",
    "    \n",
    "    # 마스크된 위치에서 예측된 토큰 중 상위 5개를 추출하고 하나를 랜덤하게 선택\n",
    "    predictions = outputs.logits\n",
    "    \n",
    "    # 마스크된 위치에서 예측된 토큰 중 최상위 1개를 추출\n",
    "    for idx in masked_indices:\n",
    "        token_logits = predictions[0, idx]\n",
    "        top_token = torch.argmax(token_logits).item()  # 최상위 토큰 1개 선택\n",
    "        replacement_token = tokenizer.decode([top_token]).strip()\n",
    "        tokens[idx] = replacement_token\n",
    "\n",
    "    # 문장 재구성\n",
    "    augmented_sentence = tokenizer.convert_tokens_to_string(tokens)\n",
    "    return augmented_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 기존의 데이터를 유지하면서 sentence_1과 sentence_2만 유의어로 교체한 데이터를 추가\n",
    "def augment_data(df):\n",
    "    augmented_data = []\n",
    "\n",
    "    # 기존 데이터를 증강하는 과정\n",
    "    for i in range(len(df)):\n",
    "        original_sentence_1 = df.loc[i, \"sentence_1\"]\n",
    "        original_sentence_2 = df.loc[i, \"sentence_2\"]\n",
    "\n",
    "        # 각 문장을 유의어로 대체\n",
    "        augmented_sentence_1 = get_synonym_replacement(original_sentence_1)\n",
    "        augmented_sentence_2 = get_synonym_replacement(original_sentence_2)\n",
    "\n",
    "        # 증강된 문장과 기존 id, source, label, binary-label 추가\n",
    "        augmented_data.append({\n",
    "            \"id\": df.loc[i, \"id\"],\n",
    "            \"sentence_1\": augmented_sentence_1,\n",
    "            \"sentence_2\": augmented_sentence_2,\n",
    "            \"source\": df.loc[i, \"source\"],\n",
    "            \"label\": df.loc[i, \"label\"],\n",
    "            \"binary-label\": df.loc[i, \"binary-label\"]\n",
    "        })\n",
    "    \n",
    "    # 기존 데이터프레임을 그대로 유지하고 증강된 데이터 추가\n",
    "    df_augmented = pd.concat([df, pd.DataFrame(augmented_data)], ignore_index=True)\n",
    "    \n",
    "    return df_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "증강된 데이터가 'augmented_train.csv'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 6. 증강된 데이터를 얻고 CSV로 저장\n",
    "df_augmented = augment_data(df)\n",
    "df_augmented.to_csv(\"./v2/full_augmented_train.csv\", index=False)\n",
    "print(\"증강된 데이터가 'augmented_train.csv'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 부분 증강을 위한 함수\n",
    "\n",
    "# 기존의 데이터를 유지하면서 label < 1인 데이터에 대해서만 sentence_1과 sentence_2를 유의어로 교체한 데이터를 추가\n",
    "def augment_partial_data(df):\n",
    "    augmented_data = []\n",
    "\n",
    "    # 기존 데이터를 증강하는 과정 (label < 1인 데이터에 대해서만)\n",
    "    for i in range(len(df)):\n",
    "        original_sentence_1 = df.loc[i, \"sentence_1\"]\n",
    "        original_sentence_2 = df.loc[i, \"sentence_2\"]\n",
    "        label = df.loc[i, \"label\"]\n",
    "\n",
    "        # label 값이 1 미만인 데이터에만 유의어 증강 적용\n",
    "        if label < 1:\n",
    "            # 각 문장을 유의어로 대체\n",
    "            augmented_sentence_1 = get_synonym_replacement(original_sentence_1)\n",
    "            augmented_sentence_2 = get_synonym_replacement(original_sentence_2)\n",
    "\n",
    "            # 증강된 문장과 기존 id, source, label, binary-label 추가\n",
    "            augmented_data.append({\n",
    "                \"id\": df.loc[i, \"id\"],\n",
    "                \"sentence_1\": augmented_sentence_1,\n",
    "                \"sentence_2\": augmented_sentence_2,\n",
    "                \"source\": df.loc[i, \"source\"],\n",
    "                \"label\": df.loc[i, \"label\"],\n",
    "                \"binary-label\": df.loc[i, \"binary-label\"]\n",
    "            })\n",
    "    \n",
    "    # 기존 데이터프레임을 그대로 유지하고 증강된 데이터 추가\n",
    "    df_augmented = pd.concat([df, pd.DataFrame(augmented_data)], ignore_index=True)\n",
    "    \n",
    "    return df_augmented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STS_final-jkMVgCRe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
